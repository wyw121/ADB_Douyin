#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
UIä¸Šä¸‹æ–‡åˆ†ææ¨¡å—
è´Ÿè´£åˆ†æå’Œæ˜¾ç¤ºå½“å‰UIçŠ¶æ€çš„å…³é”®ä¿¡æ¯ï¼Œå¸®åŠ©åˆ¤æ–­æ¨¡å—æ˜¯å¦åœ¨æ­£ç¡®çš„ç•Œé¢å·¥ä½œ
"""

import logging
import re
from typing import Dict, List, Optional, Any
from .ui_intelligence import UIAnalyzer


class UIContextAnalyzer:
    """UIä¸Šä¸‹æ–‡åˆ†æå™¨"""
    
    # æŠ–éŸ³é¡µé¢ç‰¹å¾è¯†åˆ«
    PAGE_SIGNATURES = {
        'main_feed': {
            'indicators': ['æ¨è', 'å…³æ³¨', 'ç›´æ’­', 'åŒåŸ'],
            'description': 'æŠ–éŸ³ä¸»é¡µé¢(æ¨èé¡µ)'
        },
        'profile': {
            'indicators': ['ä¸ªäººèµ„æ–™', 'ç¼–è¾‘èµ„æ–™', 'å…³æ³¨', 'ç²‰ä¸', 'è·èµ'],
            'description': 'ä¸ªäººèµ„æ–™é¡µé¢'
        },
        'add_friends': {
            'indicators': ['æ·»åŠ æœ‹å‹', 'æœç´¢ç”¨æˆ·å', 'æ‰«ä¸€æ‰«', 'é€šè®¯å½•'],
            'description': 'æ·»åŠ æœ‹å‹é¡µé¢'
        },
        'contacts': {
            'indicators': ['æ‰‹æœºé€šè®¯å½•', 'é€šè®¯å½•æœ‹å‹', 'æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°'],
            'description': 'æ‰‹æœºé€šè®¯å½•é¡µé¢'
        },
        'splash': {
            'indicators': ['å¯åŠ¨', 'åŠ è½½', 'æ¬¢è¿', 'åˆå§‹åŒ–'],
            'description': 'å¯åŠ¨ç”»é¢'
        },
        'navigation_bar': {
            'indicators': ['é¦–é¡µ', 'æœ‹å‹', 'æ¶ˆæ¯', 'æˆ‘'],
            'description': 'åº•éƒ¨å¯¼èˆªæ '
        },
        'unknown': {
            'indicators': [],
            'description': 'æœªçŸ¥é¡µé¢'
        }
    }
    
    def __init__(self):
        """åˆå§‹åŒ–UIä¸Šä¸‹æ–‡åˆ†æå™¨"""
        self.logger = logging.getLogger(__name__)
        self.ui_analyzer = UIAnalyzer()
    
    def analyze_current_context(self, xml_content: str) -> Dict[str, Any]:
        """åˆ†æå½“å‰UIä¸Šä¸‹æ–‡
        
        Args:
            xml_content: UI XMLå†…å®¹
            
        Returns:
            åŒ…å«é¡µé¢ä¿¡æ¯çš„å­—å…¸
        """
        if not xml_content:
            return self._create_empty_context("æ— æ³•è·å–UIå†…å®¹")
        
        # è§£æXML
        if not self.ui_analyzer.parse_xml(xml_content):
            return self._create_empty_context("XMLè§£æå¤±è´¥")
        
        # åˆ†æé¡µé¢ç±»å‹
        page_type = self._detect_page_type(xml_content)
        
        # æå–å…³é”®ä¿¡æ¯
        key_elements = self._extract_key_elements()
        clickable_elements = self._extract_clickable_elements()
        text_elements = self._extract_text_elements()
        
        # åˆ†æé¡µé¢å¥åº·åº¦
        health_score = self._calculate_page_health()
        
        return {
            'page_type': page_type,
            'page_description': self.PAGE_SIGNATURES[page_type]['description'],
            'total_elements': len(self.ui_analyzer.elements),
            'key_elements': key_elements,
            'clickable_elements': clickable_elements,
            'text_elements': text_elements,
            'health_score': health_score,
            'is_valid_page': health_score > 0.5,
            'xml_snippet': self._get_xml_snippet(xml_content),
            'recommendations': self._get_recommendations(page_type, health_score)
        }
    
    def _detect_page_type(self, xml_content: str) -> str:
        """æ£€æµ‹é¡µé¢ç±»å‹"""
        page_scores = {}
        
        for page_type, signature in self.PAGE_SIGNATURES.items():
            if page_type == 'unknown':
                continue
                
            score = 0
            indicators = signature['indicators']
            
            for indicator in indicators:
                if indicator in xml_content:
                    score += 1
            
            # è®¡ç®—åŒ¹é…ç‡
            if indicators:
                page_scores[page_type] = score / len(indicators)
            else:
                page_scores[page_type] = 0
        
        # æ‰¾åˆ°æœ€é«˜åˆ†çš„é¡µé¢ç±»å‹
        if page_scores:
            best_match = max(page_scores, key=page_scores.get)
            if page_scores[best_match] > 0.3:  # è‡³å°‘30%åŒ¹é…ç‡
                return best_match
        
        return 'unknown'
    
    def _extract_key_elements(self) -> List[Dict[str, Any]]:
        """æå–å…³é”®å…ƒç´ """
        key_elements = []
        
        for element in self.ui_analyzer.elements:
            # æŸ¥æ‰¾æœ‰æ–‡æœ¬çš„é‡è¦å…ƒç´ 
            if element.text and len(element.text.strip()) > 0:
                # è¿‡æ»¤å¸¸è§çš„é‡è¦å…ƒç´ 
                if any(keyword in element.text for keyword in 
                       ['æˆ‘', 'é¦–é¡µ', 'æ¨è', 'å…³æ³¨', 'æ·»åŠ æœ‹å‹', 'é€šè®¯å½•', 
                        'è¿”å›', 'ç¡®å®š', 'å–æ¶ˆ', 'æœç´¢', 'æ‰«ä¸€æ‰«']):
                    key_elements.append({
                        'text': element.text.strip(),
                        'class': element.class_name,
                        'clickable': element.clickable,
                        'bounds': element.bounds,
                        'center': element.get_center()
                    })
        
        return key_elements[:10]  # é™åˆ¶æ•°é‡
    
    def _extract_clickable_elements(self) -> List[Dict[str, Any]]:
        """æå–å¯ç‚¹å‡»å…ƒç´ """
        clickable_elements = []
        
        for element in self.ui_analyzer.elements:
            if element.clickable:
                text = element.text or element.content_desc or "æ— æ–‡æœ¬"
                clickable_elements.append({
                    'text': text.strip() if text else "æ— æ–‡æœ¬",
                    'class': element.class_name,
                    'bounds': element.bounds,
                    'center': element.get_center()
                })
        
        return clickable_elements[:15]  # é™åˆ¶æ•°é‡
    
    def _extract_text_elements(self) -> List[str]:
        """æå–æ‰€æœ‰æ–‡æœ¬å…ƒç´ """
        text_elements = []
        
        for element in self.ui_analyzer.elements:
            if element.text and len(element.text.strip()) > 0:
                text = element.text.strip()
                if len(text) < 50:  # è¿‡æ»¤è¿‡é•¿çš„æ–‡æœ¬
                    text_elements.append(text)
        
        # å»é‡å¹¶æ’åº
        return sorted(list(set(text_elements)))[:20]
    
    def _calculate_page_health(self) -> float:
        """è®¡ç®—é¡µé¢å¥åº·åº¦(0-1)"""
        if not self.ui_analyzer.elements:
            return 0.0
        
        score = 0.0
        total_elements = len(self.ui_analyzer.elements)
        
        # åŸºç¡€åˆ†æ•°ï¼šæœ‰å…ƒç´ å°±ç»™åŸºç¡€åˆ†
        if total_elements > 0:
            score += 0.3
        
        # å¯ç‚¹å‡»å…ƒç´ åˆ†æ•°
        clickable_count = sum(1 for e in self.ui_analyzer.elements 
                            if e.clickable)
        if clickable_count > 0:
            score += 0.3
        
        # æ–‡æœ¬å…ƒç´ åˆ†æ•°
        text_count = sum(1 for e in self.ui_analyzer.elements 
                        if e.text and len(e.text.strip()) > 0)
        if text_count > 0:
            score += 0.2
        
        # ç»“æ„å¤æ‚åº¦åˆ†æ•°
        if total_elements > 10:
            score += 0.2
        
        return min(score, 1.0)
    
    def _get_xml_snippet(self, xml_content: str, max_length: int = 500) -> str:
        """è·å–XMLç‰‡æ®µç”¨äºæ˜¾ç¤º"""
        if not xml_content:
            return "æ— XMLå†…å®¹"
        
        # æå–æœ‰æ„ä¹‰çš„æ–‡æœ¬èŠ‚ç‚¹
        text_pattern = r'text="([^"]+)"'
        texts = re.findall(text_pattern, xml_content)
        
        # æå–resource-id
        id_pattern = r'resource-id="([^"]+)"'
        ids = re.findall(id_pattern, xml_content)
        
        snippet_parts = []
        
        if texts:
            snippet_parts.append(f"æ–‡æœ¬å…ƒç´ : {', '.join(texts[:8])}")
        
        if ids:
            relevant_ids = [id_val for id_val in ids 
                          if any(keyword in id_val.lower() 
                                for keyword in ['title', 'btn', 'text', 'tab'])]
            if relevant_ids:
                snippet_parts.append(f"å…³é”®ID: {', '.join(relevant_ids[:5])}")
        
        snippet = " | ".join(snippet_parts)
        
        if len(snippet) > max_length:
            snippet = snippet[:max_length] + "..."
        
        return snippet or "æ— å…³é”®ä¿¡æ¯"
    
    def _get_recommendations(self, page_type: str, health_score: float) -> List[str]:
        """è·å–å»ºè®®"""
        recommendations = []
        
        if health_score < 0.3:
            recommendations.append("âš ï¸ é¡µé¢å¥åº·åº¦ä½ï¼Œå»ºè®®é‡æ–°è·å–UIæˆ–é‡å¯åº”ç”¨")
        
        if page_type == 'unknown':
            recommendations.append("â“ æœªè¯†åˆ«é¡µé¢ç±»å‹ï¼Œå¯èƒ½éœ€è¦å¯¼èˆªåˆ°æ­£ç¡®é¡µé¢")
        
        if page_type == 'splash':
            recommendations.append("ğŸ”„ æ£€æµ‹åˆ°å¯åŠ¨ç”»é¢ï¼Œå»ºè®®ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ")
        
        if not recommendations:
            recommendations.append("âœ… é¡µé¢çŠ¶æ€æ­£å¸¸")
        
        return recommendations
    
    def _create_empty_context(self, reason: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return {
            'page_type': 'unknown',
            'page_description': f'æ— æ³•åˆ†æ: {reason}',
            'total_elements': 0,
            'key_elements': [],
            'clickable_elements': [],
            'text_elements': [],
            'health_score': 0.0,
            'is_valid_page': False,
            'xml_snippet': reason,
            'recommendations': [f"âŒ {reason}"]
        }
    
    def print_context_info(self, context: Dict[str, Any], 
                          module_name: str = "UIåˆ†æ") -> None:
        """æ‰“å°ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        print(f"\nğŸ“Š {module_name} - UIä¸Šä¸‹æ–‡åˆ†æ")
        print("=" * 60)
        
        print(f"ğŸ“± é¡µé¢ç±»å‹: {context['page_description']}")
        print(f"ğŸ—ï¸ å…ƒç´ æ€»æ•°: {context['total_elements']}")
        print(f"ğŸ’¯ å¥åº·åº¦: {context['health_score']:.2f}")
        print(f"âœ… é¡µé¢æœ‰æ•ˆ: {'æ˜¯' if context['is_valid_page'] else 'å¦'}")
        
        if context['key_elements']:
            print(f"\nğŸ” å…³é”®å…ƒç´  ({len(context['key_elements'])}ä¸ª):")
            for i, elem in enumerate(context['key_elements'][:5], 1):
                print(f"  {i}. '{elem['text']}' @ {elem['center']} "
                      f"({'å¯ç‚¹å‡»' if elem['clickable'] else 'ä¸å¯ç‚¹å‡»'})")
        
        if context['text_elements']:
            print(f"\nğŸ“ é¡µé¢æ–‡æœ¬: {', '.join(context['text_elements'][:10])}")
        
        print(f"\nğŸ”¬ XMLç‰‡æ®µ: {context['xml_snippet']}")
        
        if context['recommendations']:
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in context['recommendations']:
                print(f"  {rec}")
        
        print("=" * 60)
    
    def should_restart_app(self, context: Dict[str, Any], 
                          expected_page: str = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡å¯åº”ç”¨"""
        # é¡µé¢å¥åº·åº¦å¤ªä½
        if context['health_score'] < 0.2:
            self.logger.warning("é¡µé¢å¥åº·åº¦è¿‡ä½ï¼Œå»ºè®®é‡å¯åº”ç”¨")
            return True
        
        # æ£€æµ‹åˆ°å¯åŠ¨ç”»é¢å¡ä½
        if context['page_type'] == 'splash' and context['total_elements'] < 5:
            self.logger.warning("å¯åŠ¨ç”»é¢å¡ä½ï¼Œå»ºè®®é‡å¯åº”ç”¨")
            return True
        
        # å¦‚æœæŒ‡å®šäº†æœŸæœ›é¡µé¢ï¼Œä½†å½“å‰é¡µé¢ä¸åŒ¹é…ä¸”å¥åº·åº¦ä½
        if (expected_page and 
            context['page_type'] != expected_page and 
            context['health_score'] < 0.5):
            self.logger.warning(f"æœŸæœ›é¡µé¢'{expected_page}'ä½†å½“å‰æ˜¯'"
                              f"{context['page_type']}'ï¼Œå»ºè®®é‡å¯åº”ç”¨")
            return True
        
        return False